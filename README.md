ğŸ“˜ CNN & RNN Deep Learning Project

A comprehensive Google Colab project demonstrating CNNs, LSTMs, Bidirectional LSTMs, CNNâ€“LSTM hybrids & Hyperparameter Tuning

ğŸ” Overview

This project showcases multiple deep learning architectures implemented using TensorFlow/Keras.
It includes both image classification (CNN) and text sentiment analysis (RNN) to demonstrate how deep learning models behave on different data types.

The notebook is built and executed on Google Colab, making it accessible and easy to run.

ğŸ“ Project Structure
â”œâ”€â”€ CNN (MNIST)
â”‚   â”œâ”€â”€ Data Loading
â”‚   â”œâ”€â”€ CNN Architecture
â”‚   â”œâ”€â”€ Training & Plots
â”‚   â””â”€â”€ Evaluation
â”‚
â”œâ”€â”€ RNN Models (IMDB)
â”‚   â”œâ”€â”€ Simple LSTM
â”‚   â”œâ”€â”€ Bidirectional LSTM
â”‚   â”œâ”€â”€ CNNâ€“LSTM Hybrid
â”‚   â”œâ”€â”€ Hyperparameter Tuning (Keras Tuner)
â”‚   â””â”€â”€ Model Comparison
â”‚
â””â”€â”€ README.md

ğŸ¯ Objectives

This project demonstrates:

ğŸ”¹ Convolutional Neural Networks (CNN)

Image classification on MNIST

Convolution + Pooling

Dense and Softmax layers

ğŸ”¹ Recurrent Neural Networks (RNN)

Sentiment analysis using IMDB dataset

Sequence modeling with embeddings

ğŸ”¹ Advanced Architectures

Bidirectional LSTM

CNNâ€“LSTM Hybrid

Hyperparameter Tuning using Keras Tuner

ğŸ”¹ Evaluation Tools

Accuracy curves

Validation metrics

Model comparison table (accuracy, parameters)

ğŸ§  Models Implemented
1ï¸âƒ£ CNN (MNIST)

Conv2D â†’ MaxPooling â†’ Conv2D â†’ MaxPooling â†’ Dense

Trains fast and achieves high accuracy on image data

2ï¸âƒ£ Simple LSTM (IMDB)

Embedding â†’ LSTM â†’ Dense

Learns sequential dependencies from text

3ï¸âƒ£ Bidirectional LSTM

Reads text in forward + backward direction

Improved context understanding

4ï¸âƒ£ CNNâ€“LSTM Hybrid

CNN extracts local n-gram features

LSTM reads temporal sequence

Often performs better on longer text

5ï¸âƒ£ Tuned LSTM Model

Hyperparameters tuned:

LSTM units

Dropout rate

Learning rate

ğŸ“Š Model Comparison
Model	Test Accuracy	Trainable Params
Simple LSTM	~X%	~Y
Bidirectional LSTM	~X%	~Y
CNNâ€“LSTM Hybrid	~X%	~Y
Best Tuned Model	~X%	~Y

(Values update automatically inside the notebook.)

ğŸš€ Technologies Used

Python

TensorFlow / Keras

Keras Tuner

Matplotlib

Pandas

Google Colab

â–¶ï¸ How to Run

Open the .ipynb file in Google Colab

Install required dependencies:

!pip install tensorflow keras-tuner matplotlib


Run all the cells sequentially

View results, plots, and comparison tables

ğŸ“ˆ Results Summary

CNN achieves strong accuracy on MNIST

Bidirectional LSTM shows improved performance over standard LSTM

CNNâ€“LSTM gives balanced pattern extraction + sequence modeling

Hyperparameter tuning significantly boosts performance

ğŸ“Œ Future Enhancements

Transformer-based models (BERT, GPT-style)

Data augmentation for MNIST

Attention mechanism for IMDB

Deployment via Flask or FastAPI

ğŸ·ï¸ Author
Jyothi Sasidharan
Machine Learning & AI Enthusiast
(With background in ECE, MBA HR & Marketing)
Jyothi S
Machine Learning & AI Enthusiast
(With background in ECE, MBA HR & Marketing)
